{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d76e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LASER TRIANGULATION POSE ESTIMATION - TRAINING (Google Colab)\n",
    "# ============================================================\n",
    "\n",
    "# Cell 1: Setup and Installation\n",
    "!pip install h5py pyyaml scipy transforms3d tqdm\n",
    "\n",
    "# Cell 2: Mount Google Drive (if dataset stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Cell 3: Clone Repository or Upload Files\n",
    "# Option A: Clone from GitHub\n",
    "# !git clone https://github.com/YOUR_USERNAME/laser_pose_estimation.git\n",
    "# %cd laser_pose_estimation\n",
    "\n",
    "# Option B: Upload files manually\n",
    "# Use Colab's file upload or copy from Drive\n",
    "\n",
    "# Cell 4: Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cell 5: Dataset Class\n",
    "class PoseDataset(Dataset):\n",
    "    \"\"\"Dataset for pose estimation\"\"\"\n",
    "    \n",
    "    def __init__(self, h5_path, split='train', splits_path=None):\n",
    "        self.h5_path = h5_path\n",
    "        \n",
    "        # Load splits\n",
    "        if splits_path and Path(splits_path).exists():\n",
    "            splits = np.load(splits_path)\n",
    "            self.indices = splits[split]\n",
    "        else:\n",
    "            # Use all data\n",
    "            with h5py.File(h5_path, 'r') as f:\n",
    "                self.indices = np.arange(len(f['point_clouds']))\n",
    "        \n",
    "        print(f\"{split} set: {len(self.indices)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        \n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            pc = f['point_clouds'][real_idx]  # (2048, 3)\n",
    "            pose = f['poses'][real_idx]  # (7,)\n",
    "            label = f['labels'][real_idx]\n",
    "        \n",
    "        return {\n",
    "            'point_cloud': torch.FloatTensor(pc),\n",
    "            'pose': torch.FloatTensor(pose),\n",
    "            'label': torch.LongTensor([label])\n",
    "        }\n",
    "\n",
    "# Cell 6: Load Model (paste pointnet2_model.py content here or import)\n",
    "# ... (PointNet2PoseEstimation and PoseLoss classes)\n",
    "\n",
    "# Cell 7: Training Configuration\n",
    "config = {\n",
    "    'data': {\n",
    "        'h5_path': 'data/synthetic/dataset.h5',\n",
    "        'splits_path': 'data/synthetic/splits.npz',\n",
    "        'batch_size': 32,\n",
    "        'num_workers': 2\n",
    "    },\n",
    "    'model': {\n",
    "        'input_channels': 3\n",
    "    },\n",
    "    'training': {\n",
    "        'lr': 0.001,\n",
    "        'weight_decay': 0.0001,\n",
    "        'epochs': 200,\n",
    "        'early_stopping': 20,\n",
    "        'pos_loss_weight': 1.0,\n",
    "        'rot_loss_weight': 0.1\n",
    "    },\n",
    "    'paths': {\n",
    "        'checkpoint_dir': 'checkpoints',\n",
    "        'log_dir': 'logs'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "Path(config['paths']['checkpoint_dir']).mkdir(exist_ok=True)\n",
    "Path(config['paths']['log_dir']).mkdir(exist_ok=True)\n",
    "\n",
    "# Cell 8: Initialize Data Loaders\n",
    "train_dataset = PoseDataset(\n",
    "    config['data']['h5_path'],\n",
    "    split='train',\n",
    "    splits_path=config['data']['splits_path']\n",
    ")\n",
    "\n",
    "val_dataset = PoseDataset(\n",
    "    config['data']['h5_path'],\n",
    "    split='val',\n",
    "    splits_path=config['data']['splits_path']\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['data']['num_workers']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['data']['num_workers']\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Cell 9: Initialize Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = PointNet2PoseEstimation().to(device)\n",
    "criterion = PoseLoss(\n",
    "    pos_weight=config['training']['pos_loss_weight'],\n",
    "    rot_weight=config['training']['rot_loss_weight']\n",
    ")\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['training']['lr'],\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "# Cosine annealing scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config['training']['epochs']\n",
    ")\n",
    "\n",
    "# Cell 10: Training Loop\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_pos_loss = 0\n",
    "    total_rot_loss = 0\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        pc = batch['point_cloud'].to(device)\n",
    "        gt_pose = batch['pose'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_pose = model(pc)\n",
    "        loss, pos_loss, rot_loss = criterion(pred_pose, gt_pose)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_pos_loss += pos_loss.item()\n",
    "        total_rot_loss += rot_loss.item()\n",
    "    \n",
    "    n = len(loader)\n",
    "    return total_loss/n, total_pos_loss/n, total_rot_loss/n\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_pos_loss = 0\n",
    "    total_rot_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            pc = batch['point_cloud'].to(device)\n",
    "            gt_pose = batch['pose'].to(device)\n",
    "            \n",
    "            pred_pose = model(pc)\n",
    "            loss, pos_loss, rot_loss = criterion(pred_pose, gt_pose)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_pos_loss += pos_loss.item()\n",
    "            total_rot_loss += rot_loss.item()\n",
    "    \n",
    "    n = len(loader)\n",
    "    return total_loss/n, total_pos_loss/n, total_rot_loss/n\n",
    "\n",
    "# Cell 11: Main Training Loop\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_pos_loss': [],\n",
    "    'val_pos_loss': [],\n",
    "    'train_rot_loss': [],\n",
    "    'val_rot_loss': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(config['training']['epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['training']['epochs']}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_pos, train_rot = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_pos, val_rot = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Log\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_pos_loss'].append(train_pos)\n",
    "    history['val_pos_loss'].append(val_pos)\n",
    "    history['train_rot_loss'].append(train_rot)\n",
    "    history['val_rot_loss'].append(val_rot)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} (Pos: {train_pos:.4f}, Rot: {train_rot:.4f})\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} (Pos: {val_pos:.4f}, Rot: {val_rot:.4f})\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, f\"{config['paths']['checkpoint_dir']}/best_model.pth\")\n",
    "        print(\"✓ Saved best model\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config['training']['early_stopping']:\n",
    "        print(f\"\\nEarly stopping after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "# Cell 12: Plot Training Curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.legend()\n",
    "plt.title('Total Loss')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_pos_loss'], label='Train')\n",
    "plt.plot(history['val_pos_loss'], label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Position Loss')\n",
    "plt.legend()\n",
    "plt.title('Position Loss')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['train_rot_loss'], label='Train')\n",
    "plt.plot(history['val_rot_loss'], label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Rotation Loss')\n",
    "plt.legend()\n",
    "plt.title('Rotation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['paths']['log_dir']}/training_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Training complete!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
